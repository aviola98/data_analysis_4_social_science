---
title: "Desafio_5_Viola"
author: "Aluno: André Viola"
date: "6/18/2021"
output: 
  html_document:
    df_print: paged
---

```{r, echo=FALSE}
#limpando o documento html final
knitr::opts_chunk$set(echo=FALSE,error=FALSE,warning=FALSE,message=FALSE)
```
#### Número USP: 10325940
#### Disciplina: FLS6397
#### Professor: Jonathan Peter Phillips
```{r}
#abrindo os pacotes necessários
library(geobr)
library(tidyverse)
library(tidylog)
library(crul)
library(purrr)
library(readxl)
library(sf)
library(broom)
library(Zelig)
library(pdftools)
library(ggplot2)
library(ggthemes)
library(knitr)
library(DT)
library(tidytext)
library(textstem)
library(lexiconPT)
library(wordcloud)
library(tm)
library(stargazer)
```

>Análise espacial

```{r include=FALSE}
#acessando os municípios do estado de São Paulo em 2018
SP_municipalities <-
  read_municipality(code_muni="SP",year=2018)
```

```{r include=FALSE}
#usando a funcionalidade da família map para aplicar a função read_municipality para SP,RJ,MT,RS e RN (para o ano de 2018)

estados <- c("SP","RJ","MT","RS","RN")
SP_RJ_MT_RS_RN_municipalities <- estados %>%
  map(read_municipality, 2018)
```

```{r}
#abrindo os dados da população de São Paulo em 2010

total_populacao_SP <- read_excel("total_populacao_sao_paulo.xls")
```

```{r}
#cruzando o banco da população com o banco das fronteiras dos municipios de SP

#mudando o código do municipio para dbl
total_populacao_SP[,c(1)]<- sapply(total_populacao_SP[,c(1)],as.numeric)

#mudando a variável "código do município" e "Nome do município" para "code_muni" e "name_muni" respectivamente, com a finalidade de realizar o join uma vez que estas são as chaves 

total_populacao_SP <- total_populacao_SP %>%
  rename("code_muni"="Código do município",
         "name_muni"="Nome do município")

SP_join <- SP_municipalities %>%
  left_join(total_populacao_SP, c("code_muni",
                                 "name_muni"))
```

```{r}
#calculando a proporção da população urbana total em cada município 
SP_join <- SP_join %>%
  mutate(Proporcao_total_urbano=100*(`Total da população urbana`/`Total da população 2010`))
```

```{r}
#apresentando os resultados em um mapa
SP_join %>%
  st_as_sf(coords=c("geom")) %>%
  ggplot() +
  geom_sf(aes(fill=Proporcao_total_urbano))+
  ggtitle("Mapa da proporção da população urbana com relação à população total") +
  theme_minimal()
```

> Testes estatísticos e regressões

```{r}
#teste de Shapiro para avaliar se a taxa de urbanização do município é distribuida de forma normal 

#removendo notação científica
options(scipen=999)
teste_de_normalidade <- SP_join %>%
  pull(Proporcao_total_urbano) %>%
  shapiro.test() %>%
  tidy()

teste_de_normalidade
```

O teste de Shapiro-Wilk de normalidade da Taxa de urbanização do município (Proporcao_total_urbano) tem um valor 'p' de `r teste_de_normalidade %>% pull(p.value) %>% round(3)`, indicando que tem pouca chance da distribuição ser normal para esta variável.

```{r, results='asis'}
#executando uma regressão linear para avaliar se a taxa de urbanização do município (variável dependente) é associada com a população total do município (variável independente).

linear_regression <- SP_join %>%
  lm(Proporcao_total_urbano~`Total da população 2010`,
     data=.) %>%
  stargazer(type="html",
            title="Modelo de Taxa de Urbanização e População",
            single.row=T, keep.stat=c("n"),
            dep.var.labels="Taxa de Urbanização",
            covariate.labels = "Total da População",
            header=F, dep.var.caption = "")

linear_regression
```

```{r}
#gráfico do efeito marginal(o coeficiente) da variável da população na regressão anterior e o IC do coeficiente
#rodando o teste novamente versão tidy para fazer o gráfico (não funciona com stargazer)
linear_regression_graph <-SP_join %>%
  lm(Proporcao_total_urbano~`Total da população 2010`,
     data=.) %>%
  tidy()

linear_regression_graph %>%
  #calculando o IC
  mutate(conf.lo=estimate-1.96*std.error,
         conf.hi=estimate+1.96*std.error) %>%
  filter(term!="(Intercept)") %>%
  ggplot() +
  geom_point(aes(x=term,y=estimate))+
  geom_errorbar(aes(x=term,y=estimate,ymin=conf.lo,ymax=conf.hi), width=0.1)+
  geom_hline(yintercept=0,lty=2)+
  theme_minimal()+
  ggtitle("Gráfico de Efeito Marginal da variável População")
```

>Análise de Texto

```{r}
#transformando pdf em texto simples
#abrindo o texto em um tibble no mesmo código 
discussao_camara <- tibble(pages=pdf_text("https://escriba.camara.leg.br/escriba-servicosweb/pdf/59638"))
```

```{r}
#separando o texto com str_split baseado em 'O SR.' e 'A SRA.'
#obs: '.' é caractere especial, logo usei o Escape '\\.' para encontra-lo
#TENTAR COM [O,A] SR[A]?. DEPOIS O SR\\. | A SRA\\. "[O A] SR[A]?. "
discussao_camara<-
discussao_camara %>%
  mutate(deputado=str_split(pages,"O SR.|A SRA."))
```

```{r}
#unnesting os dados para que cada fala de deputado fique separada em uma linha separada do tibble
discussao_camara <- 
discussao_camara %>%
  unnest(deputado)
```

```{r}
#Usando separate para dividir a fala de cada deputado em duas colunas: O nome do Deputado, e o Discurso, usando o seguinte string como divisor: "\\) - "
discussao_camara <-
discussao_camara %>%
  separate(deputado,"\\) - ",into=c("Deputado","Discurso"))
```

```{r}
#usando filter para remover as linhas que começam com “Sessão” na coluna de ‘Deputado’.

#como reparei que as colunas que começavam com "Sessão" em "Deputado" eram as que continham NA em seu discurso, eu simplesmente filtrei os NA na coluna Discurso
discussao_camara <-
discussao_camara %>%
  filter(!is.na(Discurso))
```

```{r}
#separando o nome do deputado do conteudo entre parentesis ao lado

discussao_camara <-
discussao_camara %>%
  separate(Deputado, " \\(", into=c("nome_deputado","spam"))
```

```{r}
#removendo colunas desnecessárias exceto nome_deputado e Discurso

discussao_camara <-
discussao_camara %>%
  select(nome_deputado,Discurso)
```

```{r}
#tokenzinando os discursos dos deputados em palavras unicas

discussao_camara <-
discussao_camara %>%
  unnest_tokens(Palavra,Discurso, strip_numeric=T)
```

```{r}
#removendo stopwords de português

#criando um banco de stopwords
stopwords <- get_stopwords(language="pt") %>%
  rename(Palavra=word) %>%
  #removendo "é"
  add_row(Palavra="é",lexicon="pessoal")

discussao_camara <-
discussao_camara %>%
  anti_join(stopwords,by="Palavra")
```

```{r}
#transformando as palavras em seus stems

discussao_camara <-
discussao_camara %>%
  mutate(stem=stem_words(Palavra,language="pt"))
```

```{r}
#gerando um wordcloud dos stems das palavras utilizadas pelos Deputados

discussao_camara %>%
  sample_n(200) %>%
  pull(stem) %>%
  wordcloud()
```

```{r}
#analise de sentimento para identificar qual Deputado usa as palavras mais otimistas e qual usa as mais pessimistas

#criando banco de sentimentos
sentimento <- oplexicon_v3.0 %>%
  select(term,polarity) %>%
  rename(Palavra=term)

#juntando os bancos
discussao_camara <-
discussao_camara %>%
  left_join(sentimento,by="Palavra")

#identificando as linhas mais otimistas e as mais pessimistas da discussão
discussao_camara %>%
  group_by(nome_deputado) %>%
  summarize(polarity=sum(polarity,na.rm=T))%>%
  arrange(-polarity) %>%
  slice(1,n()) %>%
  kable(col.names=c("Deputado","Polaridade"))
```

